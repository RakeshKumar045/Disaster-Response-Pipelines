{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# import libraries\n",
    "# import libraries\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(database_filepath):\n",
    "    engine = create_engine('sqlite:///'+database_filepath)\n",
    "    pd.read_sql(\"SELECT * FROM df\", engine)\n",
    "    df = pd.read_sql(\"SELECT * FROM df\", engine)\n",
    "    #df['genre'].value_counts()\n",
    "    X = df.message.values\n",
    "    y = df.iloc[:,4:]\n",
    "    y=y.astype(int)\n",
    "    labels = (y.columns)\n",
    "    return X, y.values,labels\n",
    "#database_filepath='data/DisasterResponse.db'\n",
    "#X, Y, category_names = load_data(database_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "- You'll find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize,)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        #('clf', RandomForestClassifier())\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def evaluate_model(model, X_test, Y_test):\n",
    "    Y_pred = model.predict(X_test)\n",
    "    col=[\"Precision\",\"Recall\",\"Accuracy\"]\n",
    "    dfCategoriesAccuracy=pd.DataFrame(columns=col)\n",
    "    dfCategoriesAccuracy.columns=col\n",
    "    from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score\n",
    "    f1=[]\n",
    "    p=[]\n",
    "    r=[]\n",
    "    a=[]\n",
    "    for c in range(0,36):\n",
    "        f1.append(f1_score(Y_test[:,c],Y_pred[:,c],average='macro'))\n",
    "        p.append(precision_score(Y_test[:,c],Y_pred[:,c],average='macro'))\n",
    "        r.append(recall_score(Y_test[:,c],Y_pred[:,c],average='macro'))\n",
    "        a.append(accuracy_score(Y_test[:,c],Y_pred[:,c]))\n",
    "    \n",
    "    dfCategoriesAccuracy.Precision=p\n",
    "    dfCategoriesAccuracy.Recall=r\n",
    "    dfCategoriesAccuracy.Accuracy=a\n",
    "    return (np.array(a).mean(),np.array(p).mean(),np.array(r).mean(),np.array(f1).mean(),dfCategoriesAccuracy)\n",
    "def save_model(model, model_filepath):\n",
    "    pickle.dump(model, open(model_filepath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model built\n",
      "Training model...\n",
      "Model Trained\n"
     ]
    }
   ],
   "source": [
    "database_filepath='DisasterResponse.db'\n",
    "X, Y, category_names = load_data(database_filepath)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "model = build_model()\n",
    "\n",
    "print('Building model...')\n",
    "print('Model built')\n",
    "model = build_model()\n",
    "print('Training model...')\n",
    "model.fit(X_train, Y_train)\n",
    "print('Model Trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the accuracy, precision and recall on both the training set and the test set. You can use sklearn's `classification_report` function here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def display_results(model, X_train, Y_train,X_test, Y_test,category_names):\n",
    "\n",
    "    accuracy, precision, recall,f1score,df=evaluate_model(model, X_train, Y_train)\n",
    "    print(\"Train Stats\")\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    print(\"precision:\",precision)\n",
    "    print(\"recall:\",recall)\n",
    "    print(\"f1score:\",f1score)\n",
    "    df.index=category_names\n",
    "    print(\"Precision, Recall and Accuracy at Category Level for Train set\\n\",df)\n",
    "    #Testing on Test Set\n",
    "    accuracy, precision, recall,f1score,dftest=evaluate_model(model, X_test, Y_test)\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Test Stats\")\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    print(\"precision:\",precision)\n",
    "    print(\"recall:\",recall)\n",
    "    print(\"f1score:\",f1score)\n",
    "    dftest.index=category_names\n",
    "    print(\"Precision, Recall and Accuracy at Category Level for Test set\\n\",dftest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stats\n",
      "Accuracy: 0.993126695389\n",
      "precision: 0.995450316705\n",
      "recall: 0.922378511707\n",
      "f1score: 0.954660796802\n",
      "Precision, Recall and Accuracy at Category Level for Train set\n",
      "                         Precision    Recall  Accuracy\n",
      "related                  0.991704  0.966697  0.991192\n",
      "request                  0.992668  0.965675  0.988272\n",
      "offer                    0.999424  0.866667  0.998851\n",
      "aid_related              0.985139  0.979738  0.982863\n",
      "medical_help             0.993817  0.926614  0.988463\n",
      "medical_products         0.994337  0.911336  0.991336\n",
      "search_and_rescue        0.996029  0.900638  0.994208\n",
      "security                 0.997479  0.858696  0.995022\n",
      "military                 0.997931  0.938053  0.995979\n",
      "child_alone              1.000000  1.000000  1.000000\n",
      "water                    0.996274  0.962490  0.995165\n",
      "food                     0.996000  0.976605  0.994639\n",
      "shelter                  0.995798  0.958742  0.992772\n",
      "clothing                 0.996644  0.908614  0.997319\n",
      "money                    0.996892  0.919330  0.996362\n",
      "missing_people           0.998841  0.896104  0.997702\n",
      "refugees                 0.996532  0.899286  0.993250\n",
      "death                    0.996984  0.936181  0.994208\n",
      "other_aid                0.988363  0.925519  0.980326\n",
      "infrastructure_related   0.992058  0.897592  0.986596\n",
      "transport                0.995238  0.895991  0.990809\n",
      "buildings                0.995873  0.922462  0.992101\n",
      "electricity              0.997763  0.890215  0.995596\n",
      "tools                    0.999230  0.877863  0.998468\n",
      "hospitals                0.998601  0.871681  0.997224\n",
      "shops                    0.999376  0.867347  0.998755\n",
      "aid_centers              0.995611  0.863430  0.996697\n",
      "other_infrastructure     0.994627  0.881291  0.989612\n",
      "weather_related          0.990582  0.976706  0.986836\n",
      "floods                   0.994865  0.952429  0.992149\n",
      "storm                    0.996571  0.971915  0.994639\n",
      "fire                     0.998528  0.864444  0.997080\n",
      "earthquake               0.995080  0.977784  0.995452\n",
      "cold                     0.995709  0.925185  0.996841\n",
      "other_weather            0.995149  0.910764  0.990713\n",
      "direct_report            0.990496  0.961544  0.985065\n",
      "------------------------------------------------------------------------\n",
      "Test Stats\n",
      "Accuracy: 0.941030059353\n",
      "precision: 0.776123497709\n",
      "recall: 0.578481110264\n",
      "f1score: 0.596584878583\n",
      "Precision, Recall and Accuracy at Category Level for Test set\n",
      "                         Precision    Recall  Accuracy\n",
      "related                  0.658847  0.487112  0.793605\n",
      "request                  0.848263  0.666031  0.872679\n",
      "offer                    0.497415  0.500000  0.994831\n",
      "aid_related              0.733388  0.696364  0.724871\n",
      "medical_help             0.745257  0.531191  0.918438\n",
      "medical_products         0.958561  0.551738  0.948497\n",
      "search_and_rescue        0.727618  0.540939  0.977025\n",
      "security                 0.490134  0.499707  0.979705\n",
      "military                 0.758855  0.529834  0.966111\n",
      "child_alone              1.000000  1.000000  1.000000\n",
      "water                    0.888618  0.656690  0.949071\n",
      "food                     0.868008  0.702114  0.921118\n",
      "shelter                  0.881500  0.631634  0.927819\n",
      "clothing                 0.990613  0.514851  0.981237\n",
      "money                    0.916014  0.521800  0.974727\n",
      "missing_people           0.827203  0.515055  0.987555\n",
      "refugees                 0.690035  0.519359  0.966494\n",
      "death                    0.913629  0.541366  0.957304\n",
      "other_aid                0.710559  0.513957  0.868658\n",
      "infrastructure_related   0.800670  0.502813  0.934520\n",
      "transport                0.798558  0.519689  0.949071\n",
      "buildings                0.862335  0.556564  0.954049\n",
      "electricity              0.989468  0.504505  0.978939\n",
      "tools                    0.497320  0.500000  0.994639\n",
      "hospitals                0.494543  0.500000  0.989087\n",
      "shops                    0.497894  0.500000  0.995788\n",
      "aid_centers              0.494256  0.500000  0.988512\n",
      "other_infrastructure     0.477669  0.499399  0.954241\n",
      "weather_related          0.836867  0.738393  0.835918\n",
      "floods                   0.924739  0.665097  0.940456\n",
      "storm                    0.849370  0.663889  0.930883\n",
      "fire                     0.828065  0.517447  0.989278\n",
      "earthquake               0.931981  0.817816  0.958070\n",
      "cold                     0.900457  0.545259  0.982386\n",
      "other_weather            0.849226  0.530861  0.947540\n",
      "direct_report            0.802510  0.643846  0.843959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "display_results(model, X_train, Y_train,X_test, Y_test,category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=-1))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__ngram_range': ((1, 1), (1, 2)), 'clf__estimator__n_estimators': [20, 30], 'clf__estimator__min_samples_split': [2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        #'vect__max_df': (0.5, 1.0),\n",
    "        #'vect__max_features': (None, 5000),\n",
    "        #'tfidf__use_idf': (True, False),\n",
    "        'clf__estimator__n_estimators': [20, 30],\n",
    "        'clf__estimator__min_samples_split': [2, 3],\n",
    "    }\n",
    "\n",
    "cv = GridSearchCV(build_model(), param_grid=parameters)\n",
    "cv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'clf__estimator__min_samples_split': 2, 'clf__estimator__n_estimators': 30, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "#clf.get_params().keys()\n",
    "print(\"\\nBest Parameters:\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stats\n",
      "Accuracy: 0.987882293495\n",
      "precision: 0.988434814498\n",
      "recall: 0.901077713611\n",
      "f1score: 0.939100512338\n",
      "Precision, Recall and Accuracy at Category Level for Train set\n",
      "                         Precision    Recall  Accuracy\n",
      "related                  0.958906  0.875814  0.958066\n",
      "request                  0.980017  0.941539  0.978124\n",
      "offer                    0.999424  0.866667  0.998851\n",
      "aid_related              0.951764  0.941370  0.948013\n",
      "medical_help             0.988264  0.892023  0.982719\n",
      "medical_products         0.986602  0.893237  0.989086\n",
      "search_and_rescue        0.993392  0.884860  0.993202\n",
      "security                 0.997648  0.868207  0.995357\n",
      "military                 0.992651  0.891494  0.992772\n",
      "child_alone              1.000000  1.000000  1.000000\n",
      "water                    0.988393  0.930073  0.990522\n",
      "food                     0.985027  0.946858  0.986788\n",
      "shelter                  0.987358  0.926136  0.986357\n",
      "clothing                 0.985491  0.880253  0.996266\n",
      "money                    0.996086  0.888148  0.994974\n",
      "missing_people           0.998648  0.878788  0.997319\n",
      "refugees                 0.992485  0.887758  0.992293\n",
      "death                    0.987277  0.896324  0.990043\n",
      "other_aid                0.979811  0.884005  0.968980\n",
      "infrastructure_related   0.990263  0.878789  0.984107\n",
      "transport                0.993166  0.895374  0.990618\n",
      "buildings                0.992482  0.902155  0.989852\n",
      "electricity              0.998126  0.908115  0.996314\n",
      "tools                    0.999206  0.874046  0.998420\n",
      "hospitals                0.998288  0.842920  0.996601\n",
      "shops                    0.999256  0.841837  0.998516\n",
      "aid_centers              0.995805  0.873470  0.996936\n",
      "other_infrastructure     0.991773  0.881191  0.989421\n",
      "weather_related          0.971770  0.951944  0.969555\n",
      "floods                   0.989888  0.912207  0.985448\n",
      "storm                    0.978967  0.934687  0.985543\n",
      "fire                     0.995831  0.882198  0.997415\n",
      "earthquake               0.983049  0.964590  0.991288\n",
      "cold                     0.992290  0.904108  0.995883\n",
      "other_weather            0.989912  0.889428  0.988176\n",
      "direct_report            0.974340  0.928186  0.969938\n",
      "------------------------------------------------------------------------\n",
      "Test Stats\n",
      "Accuracy: 0.98644882677\n",
      "precision: 0.987777670539\n",
      "recall: 0.890215447917\n",
      "f1score: 0.931830465396\n",
      "Precision, Recall and Accuracy at Category Level for Test set\n",
      "                         Precision    Recall  Accuracy\n",
      "related                  0.951550  0.857145  0.958644\n",
      "request                  0.976049  0.924991  0.971664\n",
      "offer                    0.999423  0.888889  0.998851\n",
      "aid_related              0.952497  0.941874  0.948114\n",
      "medical_help             0.985872  0.889987  0.981237\n",
      "medical_products         0.988189  0.876051  0.985449\n",
      "search_and_rescue        0.997078  0.873950  0.994256\n",
      "security                 0.997184  0.859223  0.994448\n",
      "military                 0.995481  0.871508  0.991193\n",
      "child_alone              1.000000  1.000000  1.000000\n",
      "water                    0.989109  0.918002  0.988321\n",
      "food                     0.981861  0.931037  0.982386\n",
      "shelter                  0.989648  0.920622  0.985066\n",
      "clothing                 0.998346  0.915842  0.996745\n",
      "money                    0.997165  0.894161  0.994448\n",
      "missing_people           0.989483  0.901418  0.997320\n",
      "refugees                 0.984044  0.868889  0.990810\n",
      "death                    0.991401  0.876983  0.988512\n",
      "other_aid                0.978507  0.872857  0.965920\n",
      "infrastructure_related   0.990040  0.883279  0.984492\n",
      "transport                0.988102  0.870647  0.986215\n",
      "buildings                0.988729  0.879109  0.987555\n",
      "electricity              0.996503  0.837838  0.993107\n",
      "tools                    0.999231  0.857143  0.998468\n",
      "hospitals                0.998456  0.859649  0.996937\n",
      "shops                    0.999232  0.818182  0.998468\n",
      "aid_centers              0.998167  0.841667  0.996362\n",
      "other_infrastructure     0.992321  0.892604  0.990235\n",
      "weather_related          0.972004  0.950498  0.968792\n",
      "floods                   0.987510  0.893935  0.981620\n",
      "storm                    0.983558  0.930009  0.986023\n",
      "fire                     0.998264  0.842105  0.996554\n",
      "earthquake               0.983017  0.956816  0.989470\n",
      "cold                     0.976637  0.853243  0.993873\n",
      "other_weather            0.993503  0.886364  0.987555\n",
      "direct_report            0.971834  0.911240  0.963048\n"
     ]
    }
   ],
   "source": [
    "display_results(cv, X_train, Y_train,X_test, Y_test,category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "    MODEL: bestmodel.pkl\n"
     ]
    }
   ],
   "source": [
    "model_filepath=\"bestmodel.pkl\"\n",
    "print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "save_model(cv, model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
